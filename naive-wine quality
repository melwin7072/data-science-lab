import pandas as pd 
df = pd.read_csv('/content/Wine_Quality.csv') 
print(df.head())    # Check the first few rows 
print(df.isnull().sum())   # Check for missing values 
print(df.describe())  # Summary statistics of the dataset 
print(df['quality'].value_counts()) 

import matplotlib.pyplot as plt 
import seaborn as sns 
# (i) Histogram for a feature like 'alcohol' 
plt.figure(figsize=(8, 6)) 
df['alcohol'].hist(bins=30) 
plt.title("Histogram of Alcohol") 
plt.xlabel("Alcohol") 
plt.ylabel("Frequency") 
plt.show() 
# (ii) Box plot for 'alcohol' grouped by 'quality' 
plt.figure(figsize=(8, 6)) 
sns.boxplot(x='quality', y='alcohol', data=df) 
plt.title("Box plot of Alcohol grouped by Quality") 
plt.show() 

 Implement Na√Øve Bayes Classification 
from sklearn.model_selection import train_test_split 
from sklearn.naive_bayes import GaussianNB 
from sklearn.metrics import classification_report, accuracy_score 
from sklearn.impute import SimpleImputer # import the imputer 

X = df.drop(columns=['type', 'quality', 'quality_label']) 
y = df['quality_label'] 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
random_state=42) 
imputer = SimpleImputer(strategy='mean') # create an imputer object with strategy 'mean' 
X_train = imputer.fit_transform(X_train) # fit and transform on the training data 
X_test = imputer.transform(X_test) # transform the test data  
# Step 5: Train the Naive Bayes classifier 
nb_model = GaussianNB() 
nb_model.fit(X_train, y_train) 
# Step 6: Make predictions on the test set 
y_pred = nb_model.predict(X_test) 
# Step 7: Evaluate the model 
accuracy = accuracy_score(y_test, y_pred) 
classification_rep = classification_report(y_test, y_pred) 
print("Accuracy: {:.2f}%".format(accuracy * 100)) 
print("\nClassification Report:\n", classification_rep)
